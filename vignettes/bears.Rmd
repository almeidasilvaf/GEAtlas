---
title: "bears: building expression atlases in R"
author: 
  - name: Fabricio Almeida-Silva
    affiliation: Universidade Estadual do Norte Fluminense Darcy Ribeiro, RJ, Brazil
  - name: Thiago Motta Venancio
    affiliation: Universidade Estadual do Norte Fluminense Darcy Ribeiro, RJ, Brazil
output: 
  BiocStyle::html_document:
    self_contained: yes
    toc: true
    toc_depth: 2
    number_sections: yes
    code_folding: show
date: "`r Sys.Date()`"
vignette: >
  %\VignetteIndexEntry{Building expression atlases in R}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    crop = NULL ## Related to https://stat.ethz.ch/pipermail/bioc-devel/2020-April/016656.html
)
```


# Introduction

In the past decades, there has been an exponential accumulation of RNA-seq
data in public repositories. This steep increase paved the way to the creation
of gene expression atlases, which consist in comprehensive collections of
expression data from public databases, analyzed with a single pipeline for
consistency and across-project comparison. `bears` is a package that allows
you to create your own gene expression atlas for a given species using
public data. The package features:

- Data download from NCBI's Sequence Read Archive (SRA) or the European
Nucleotide Archive (ENA).
- Sequence quality check and trimming of low-quality sequences.
- Removal of rRNA, which are typical problems of libraries that were prepared
with the rRNA depletion protocol.
- Read mapping against a reference genome.
- Transcript assembly.
- Quantification of gene and transcript expression with 
either **alignment-based** or **alignment-free** methods.

# Installation and setup

To install `bears`, use the following code:

```{r install, eval = FALSE}
remotes::install_github("almeidasilvaf/bears")
```

Then, create a standard directory structure with `create_dir_structure()` to
store your results. This is optional, 
but **it will make your life much easier.** The output is a list of paths to
common directories that you will need to specify in several functions of this
package.

```{r setup_dir}
library(bears)

# Create directory structure using a temporary directory as root
ds <- create_dir_structure(rootdir = tempdir())

# Look at the output
ds
```

# Retrieve sample metadata

First of all, you need to choose which samples you want to download and create
a **metadata data frame** for your samples. To create this data frame, you will
pass a search term to the function `create_sample_info()`. The search term
has the same syntax of the SRA search term syntax. For example, you can search
by:

- BioSample accession - **SAMN08903403[BSPL]**
- BioProject accession - **PRJNA229998[GPRJ]**
- All BioSamples for an organism - **Glycine max[ORGN] AND RNA-seq[STRA]**
- And so on...

Let's create a metadata data frame for a human RNA-seq sample that is included
in the {airway} Bioconductor package.

```{r sample_metadata}
# Create metadata data frame
term <- "SAMN02422669[BSPL]"
metadata <- create_sample_info(term)
metadata
```

# Download FASTQ files

To download the .fastq files with the reads, you have 2 options:

- Using `download_fastq()`, which relies on the popular SRA Toolkit to 
download reads from NCBI's SRA. You need to have SRA Toolkit installed 
in your machine to run this function.
- Using `download_from_ena()` (recommended), which downloads reads from ENA. 
This function does not require any external dependency and it is much
faster than using SRA Toolkit.

As input, you only need to give the metadata data frame and the path
the output directory where .fastq files will be stored. For example:

```{r download_from_ena, eval = FALSE}
# Download sample to temporary directory
options(timeout = 6000)
download <- download_from_ena(metadata, fastqdir = ds$fastqdir)
```

# Sequence quality check and trimming

After downloading the .fastq files, you need to perform some quality checks
to check if you don't have poor-quality base calling or sequence adapters. 
These can be done with the function `run_fastqc()`, which (guess what?) 
runs FastQC from the R session. FastQC results can then be summarized 
with MultiQC.

```{r echo=FALSE}
# For running time issues, copy example FASTQ files to ds$fastqdir
f <- list.files(system.file("extdata", package = "bears"), 
                pattern = ".fastq.gz")
file.copy(f, ds$fastqdir)
```

```{r run_fastqc}
data(fastqc_table)

# Run FastQC for all .fastq files in fastqdir
multiqc_out <- file.path(tempdir(), "multiqc")
if(fastqc_is_installed() & multiqc_is_installed()) {
    fastqc <- run_fastqc(
        metadata, 
        fastqdir = ds$fastqdir, 
        fastqcdir = ds$fastqcdir
    )
    fastqc_table <- multiqc(ds$fastqcdir, multiqc_out)
}

# Look at the summary output
fastqc_table
```

# Read filtering

Read filtering consists in 2 steps:

1. `trim_reads()` - trim adapters and low-quality bases. This function
runs Trimmomatic from an R session and saves filtered .fastq files in a 
directory named `filtdir`.
2. `remove_rrna()` - remove rRNA from .fastq files, if there are any. rRNA
removal relies on the SortMeRNA program.

Here, as you can see in the *fastqc_table* above, the files passed the "Per
Base Sequence Quality" check, so we don't need to trim anything. For this
particular case, we can skip `trim_reads()` and only run `remove_rrna()`.
As rRNA database, we will create a directory and store an example rRNA file
in it.

```{r remove_rrna}
# Specify path to rRNA db
rrna_db_dir <- file.path(tempdir(), "rrna")
dir.create(rrna_db_dir)
rrna_file <- system.file("extdata", "bac_16s_subset.fa", package="bears")
file.copy(from = rrna_file, to = rrna_db_dir)

# Run SortMeRNA
options(timeout = 200)
if(sortmerna_is_installed()) {
    remove_rrna(
        metadata, 
        fastqdir = ds$fastqdir,
        filtdir = ds$filtdir,
        rrna_db_dir = rrna_db_dir
    )
}
```

Now that we have performed all quality checks, we're good to go. [^1]

[^1]: **NOTE:** After running `remove_rrna()`, filtered .fastq files are stored
in the directory specified in `filtdir`. If you think this step is not 
necessary for your data set and want to skip it, the `filtdir` directory will
remain empty, so all your .fastq files will be stored in `fastqdir`. Keep this
in mind when specifying the path to .fastq files in the following steps of
the pipeline.


# Read mapping (optional)

Read mapping is only required if you want to quantify the expression with
alignment-based methods (e.g., StringTie and featureCounts) or 
if you want to assemble transcripts. In `bears`, reads are mapped to the
reference genome with STAR.

Here, for the purpose of demonstration, we will map reads to a subset of the
human genome. The FASTA and GTF files corresponding to the subset of the genome
are available in /extdata.

Before mapping reads, we need to create a genome index. This can be done 
with `star_genome_index()`.

```{r star_genome_index}
# Get paths to genome subset
genome_path <- system.file("extdata", "Hsapiens_GRCh37.75_subset.fa", 
                            package="bears")
gff_path <- system.file("extdata", "Homo_sapiens.GRCh37.75_subset.gtf", 
                         package="bears")

# Create genome index
if(star_is_installed()) {
    star_genome_index(genome_path, gff_path, ds$mapping_dir)
}
```

Now that we have the genome index, we can map reads to it.

```{r star_align}
if(star_is_installed()) {
    star_align(
        metadata, 
        filtdir = ds$filtdir, 
        fastqc_table = fastqc_table, 
        mappingdir = ds$mappingdir,
        gff_path = gff_path
    )
}
```

Finally, let's get mapping stats.

```{r mapping_stats}
if(multiqc_is_installed()) {
    star_stats <- multiqc(dir = ds$mappingdir,
                          outdir = tempdir(),
                          runon = "star")
    
    # Check if samples passed the filtering criterion
    align_passed <- mapping_pass(star_stats, sample_info)
}
```

# Quantification

Before quantification, we need to infer library strandedness.

```{r eval = FALSE}
# Convert GFF to BED
gff2bed(gffpath = "data/Gmax_a2.v1.gff3")

# Infer strandedness
sample_info2 <- infer_strandedness(
  mapping_passed = align_passed,
  bedpath = "data/Gmax_a2.v1.bed",
  mappingdir="results/04_read_mapping"
  )

```

# Session information {.unnumbered}


# References {.unnumbered}
