---
title: "bears: building expression atlases in R"
author: 
  - name: Fabricio Almeida-Silva
    affiliation: Universidade Estadual do Norte Fluminense Darcy Ribeiro, RJ, Brazil
  - name: Thiago Motta Venancio
    affiliation: Universidade Estadual do Norte Fluminense Darcy Ribeiro, RJ, Brazil
output: 
  BiocStyle::html_document:
    self_contained: yes
    toc: true
    toc_depth: 2
    number_sections: yes
    code_folding: show
date: "`r Sys.Date()`"
vignette: >
  %\VignetteIndexEntry{Introduction to bears}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}  
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
    collapse = TRUE,
    comment = "#>",
    eval = FALSE,
    crop = NULL ## Related to https://stat.ethz.ch/pipermail/bioc-devel/2020-April/016656.html
)
```


# Introduction

# Retrieve sample metadata

```{r}
# Single-end example data
term_se <- "SAMN08903403[BSPL]"
df_se <- create_sample_info(term_se)

# Paired-end example data
term_pe <- "SAMD00117551[BSPL]"
df_pe <- create_sample_info(term_pe)

# SOLiD example data
term_solid <- "SAMN02688407[BSPL]"
df_solid <- create_sample_info(term_solid)

# Combine data frames
sample_info <- rbind(df_se, df_pe, df_solid)

dput(sample_info)

# Test for all biosamples in soybean
#df_test <- create_sample_info("Glycine max[ORGN] AND RNA-seq[STRA] AND 2021[PDAT]")
```

# Download FASTQ files

```{r}
download_fastq(sample_info[1, ], threads = 30)
```

# Running FastQC

```{r}
run_fastqc(sample_info[c(1,2), ])
```

Now, let's check FastQC results.

```{r}
fastqc_table <- multiqc()
```

# Read filtering

Let's trim adapters and low-quality reads with Trimmomatic.

```{r}
trim_reads(sample_info, fastqc_table)
```

Now, let's remove possible rRNA from reads.

```{r}
options(timeout = 200)
remove_rrna(sample_info, threads = 40)
```

# Read mapping

First of all, let's create a directory `data/` with genome sequences, gene annotation, and other required input data.

```{r}
# Create directory
dir.create("data")

# Download GFF file
download.file("ftp://ftp.psb.ugent.be/pub/plaza/plaza_public_dicots_04/GFF/gma/annotation.all_transcripts.all_features.gma.gff3.gz",
              destfile = "data/Gmax_a2.v1.gff3.gz")

# Download genome sequence
download.file("ftp://ftp.psb.ugent.be/pub/plaza/plaza_public_dicots_04/Genomes/gma.con.gz", destfile = "data/Gmax_a2.v1.fa.gz")
```

```{bash}
# Unzip and clean files
gunzip data/*.gz
sed -i '/^#/d' data/Gmax_a2.v1.gff3
sed -i 's/JGI /JGI_/g' data/Gmax_a2.v1.gff3
```

Now, we will create a genome index for faster read mapping.

```{r}
star_genome_index(genome_path = "data/Gmax_a2.v1.fa",
                  gff_path = "data/Gmax_a2.v1.gff3",
                  mappingdir = "results/04_read_mapping",
                  indexdir = "results/04_read_mapping/genomeIndex",
                  threads = 20)
```

Finally, we can map reads to the reference genome.

```{r}
star_align(sample_info,
          fastqc_table = fastqc_table,
          gff_path = "data/Gmax_a2.v1.gff3",
          threads = 20)
```

Now, let's map SOLiD reads against the genome.

```{r}
solid_align(sample_info, genome_path = "data/Gmax_a2.v1.fa")
```

Finally, let's get mapping stats.

```{r}
star_stats <- multiqc(dir = "results/04_read_mapping",
                      outdir = "results/multiqc/star",
                      runon = "star")
align_passed <- mapping_pass(star_stats, sample_info)
```

# Quantification

Before quantification, we need to infer library strandedness.

```{r}
# Convert GFF to BED
gff2bed(gffpath = "data/Gmax_a2.v1.gff3")

# Infer strandedness
sample_info2 <- infer_strandedness(
  mapping_passed = align_passed,
  bedpath = "data/Gmax_a2.v1.bed",
  mappingdir="results/04_read_mapping"
  )

```

# Session information {.unnumbered}


# References {.unnumbered}
